# Deep_Learning
### Why?
- Big Data, GPU, and better algorithms and techniques
- TensorFlow and PyTorch are Deep Learning frameworks/ libraries

### Human Neuron â€“Signaling Mechanism
1. Excitatory stimuli reach the neuron
   - Input
2. Threshold is reached
3. Neuron fires and triggers an action potential
   - Output
     
### The Perceptron
- The structural building block of deep learning
- Forward Propagation
  - output = nonlinear activation function *( bias +  Î£ summation og all (weight*inputs))
  - y = sigma * summation( Wi*xi +b)
- Loss Function: Comparision metric between predicted output  and actual output
  - cross-entropy loss: (-y * log(Âµ(x,w))) - ((1-y) * log(1-Âµ(x,w)))
- activation Function (Threshold) :
  1. Sigmoid
     - Ïƒ(x) = 1 / (1 + exp(-x))
  2. Hyperbolic Tangent
     - Ïƒ(x) = tanh(x)
  3. ReLU - Rectified Linear Unit
     - Ïƒ(x) = max(x,0)    
- The purpose of activation functions is to introduce non-linearities to the network

![Screenshot 2024-02-14 175705](https://github.com/Selvam-DG/Deep_Learning/assets/98681717/68664083-00c7-4ec1-8cb9-18f7485eaca9)

### Multilayer Perceptron
- A multilayer perceptron is a neural network with multiple perceptrons
- It is oftentimes organized into layers
- Each layer has its own set of parameters (weights ğ‘¾ğ‘– and bias ğ’ƒğ‘–)
- The underlying computation is a matrix multiplication described by ğ’šğ‘–+1 = ğœ(ğ‘¾ğ‘– â‹…ğ’šğ‘– +ğ’ƒğ‘–)


![Screenshot 2024-02-14 175757](https://github.com/Selvam-DG/Deep_Learning/assets/98681717/cf69a10c-8bba-4d8e-8abc-af76484a4a61)

- z = ğœ(ğ‘¾1â‹…ğ’™+ğ’ƒ1)
- y = ğœ(ğ‘¾2â‹…z+ğ’ƒ2)
- Y = ğœ(ğ‘¾2â‹…(ğœ ğ‘¾1â‹…ğ’™+ğ’ƒ1) +ğ’ƒ2)

  
- Dense layer:
  - All inputs are densely connected to all outputs, these layers are known as dense layer
#### The Loss Function
 - We need a comparison metric between the predicted outputs ğ’šğ‘– and the expected outputs ğ’šğ‘–
 - This is called the loss function, which usually depends on the type of problem the multilayer perceptron solves
   - For regression, a common metric is the mean squared error
   - For classification, a common metric is the cross-entropy
- Quantifying loss:
  - The loss of our network measures the cost incurred from incorrect predictions
  - L(f(x;W),y) i.e, L(predicted value, actual value)
- Empirical Loss
  - It measures the total loss over our entire dataset
  - an average of all loss
  - J(W) = (1/n) *  Î£L(f(x;W),y)
- Binary cross-entropy loss
  - cross-entropy loss can be used with models whose output probabilities are between 0 and 1
  - J(W) = cross-entropy loss: (Î£(-y^i * log(f(x^i,W))) - ((1-y^i) * log(1-f(x^i,W))) ) / n
- Mean Squared Error Loss
  - sum of the square of the difference between actual and predicted  output values
  - J(W) = (1/n) * Î£( y^i - f(x^i,W) )^2 


#### Cross Entropy â€“ Class Probability and Softmax
- For classification, each output ğ‘¦1,â€¦,ğ‘¦ğ‘› represents a class energy
- If the target class index is ğ‘–, then only ğ‘¦ğ‘– = 1 and all other ğ‘¦ğ‘— = 0,ğ‘– â‰  ğ‘— (this is also called one-hot encoding)
  - Example for class 1: ğ‘¦ = (1 0 0 0 0)'
  - Example for class 3: ğ‘¦ = ( 0 0 1 0 0)'
- To ensure that we have probabilities, we apply a softmax transformation
  -  ğ‘¦ğ‘– =exp(ğ‘¦ğ‘–) / Î£exp(ğ‘¦ğ‘—)

- General weaknesses of Gradient Descend
  - Multiple local minima are common
  - Into which the network converges to depends heavily on random initialization
  - Success depends on learning rate


- How wrong is the current set of parameters ğœ½? Forward Propagation
  - In the forward prop, the output of the previous layer is updated to the current layer
- How should we change the set of parameters by âˆ‡ğœ½? Backward Propagation
  - In backward propagation, the weights are updated to the previous layer

### Loss Optimization
- we want to find the network weight that achieves the  lowest loss
- **W*** = argmin J(W) = argmin (1/n) *  Î£L(f(x^i;W),y^i)

### Parameter Optimization
- At this stage, we can compute the gradient of the parameters âˆ‡ğœ½
- The gradient tells us how we need to change the current parameters ğœ½ in order to make fewer errors on the given data
- We can use this in an iterative algorithm called gradient descent, with the central equation being ğœ½^i+1 = ğœ½^ğ‘– âˆ’ğœ‡â‹…âˆ‡ğœ½^ğ‘–
- The learning rate ğœ‡ tells us how quickly we should change the current parameters ğœ½^i
 - limitations:
   - The learning rate ğœ‡ can lead to slow convergence if not properly configured
   - Large learning rates result in overshoot, become unstable, and diverge
   - Slow learning rates converge slowly and get stuck to false local minima
   - Stable learning rates converge smoothly and avoid local minima
  - Adaptive learning rates are good

- Gradient Descent
  - Gradient Descent incrementally adjusts the parameters ğœ½ based on the gradient âˆ‡ğœ½ of the parameters
     - For each iteration
       1. Compute the error of the parameters ğœ½
       2. Compute the gradient of the parameters âˆ‡ğœ½
       3. Update parameters using ğœ½^ğ‘–+1 = ğœ½^ğ‘– âˆ’ ğœ‡ â‹… âˆ‡ğœ½^i
 - There is no guarantee that the algorithm converges to the global optimum (e.g., due to learning rate ğœ‡ or initial parameters ğœ½^1)
###Ã¤ Gradient Descent Algorithm
- SGD ( Stochastic Gradient Descent)
- Adam
- Adadelta
- Adagrad
- RMSProp
- **Stochastic Gradient Descent**
   - Algorithm
     - Initialize weights randomly
     - Loop until convergence
     -    pick a single data point i
     -    compute gradients
     -    update weights
     - Return weights


### How do our models learn?
- We thus need to loop over the training data ğ’™1, ğ’š1,â€¦,ğ’™ğ‘›,ğ’šğ‘›) to compute sums over individual data points 
- This results in a slight modification to the gradient descent algorithm
 1. For each epoch â€“ Loop over training data
   2. For each batch â€“ Loop over pieces of training data
     3. Compute the error of the parameters ğœ½
     4. Compute the gradient of the parameters âˆ‡ğœ½
     5. update parameters using ğœ½^ğ‘–+1 = ğœ½^ğ‘– âˆ’ ğœ‡ â‹… âˆ‡ğœ½^i

- **The Concept of Epochs**
  - Gradient descent requires multiple iterations to reach a minimum
  - The optimization function ğ‘“(ğœ½) individual data point sums the loss functions ğ¿(ğ’š^ğ‘–,ğ’šğ‘–) of each (xğ‘–, ğ’šğ‘–) in the training data
  - We need to go through the training data multiple times to find suitable parameters ğœ½ for our problem
  - Each such iteration is called an epoch
  - Requires the computation of the full sum, which is expensive
 
- **The Concept of Batches**:
  - Instead of computing the full sum of one epoch in one go, we instead break it apart into multiple smaller pieces
  - These pieces are usually of a specified size (e.g., 64), which tells us how many training data points to use for each piece
  - One epoch then consists of processing all the pieces
  - Each such piece of the training data is called a batch

- **The Learning Process â€“ A Summary**
  - The parameters ğœ½ are optimized by iterating through the training data
  - For practical reasons, this is split into epochs and batches

### The problem of Overfitting
#### Regularization:
- It is a Technique that constrains our optimization problem to discourage complex models
- We need this technique to improve the generalization of our model on unseen data
- There are two regularizations to avoid overfitting
  1. Regularization 1- Dropout
     - During training, randomly set some activations to 0
  2. Regularization 2- Early stopping
     - Stop training before we have a chance to overfit







sources: FAU University, learnbay, google, MIT_DeepLearning 





